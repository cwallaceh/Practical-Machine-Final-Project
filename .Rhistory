for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
mean(dataclt)
sd(dataclt)
set.seed(5)
estimated = rexp(1000, lambda)
x = seq(from = round(min(estimated)), to = round(max(estimated)), length.out = 1000)
ggplot(as.data.frame(estimated), aes(x=estimated)) +
geom_histogram(aes(y=..density..),binwidth=1,colour="black", fill="white") +
stat_function(fun = function(x) lambda * exp(-1*lambda*x),colour = "blue") +
labs(title = "Exponential Distribution, Theoretical (blue) vs Sample", x = "x", y = "Density")
mean(estimated)
sd(estimated)
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.25,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = mean(dataclt), sd = sd(dataclt), log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
mean(dataclt)
sd(dataclt)
for (i in 1 : 1000) dataclt[i] = mean(rexp(400, lambda))
sd(dataclt)
sd(dataclt)
sd(dataclt)
sd(dataclt)
sd(dataclt)
for (i in 1 : 10000) dataclt[i] = mean(rexp(40, lambda))
sd(dataclt)
for (i in 1 : 100000) dataclt[i] = mean(rexp(40, lambda))
sd(dataclt)
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.25,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = mean(dataclt), sd = sd(dataclt), log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
sd(dataclt)^2
?dnorm
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.25,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = 0.625, log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
mean(dataclt)
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
#Theorical points
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.1,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = sd(dataclt), log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
#Theorical points
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.2,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = 0.625, log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
#Theorical points
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.15,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = 0.625, log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
#Theorical points
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.1,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = 0.625, log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
#Theorical points
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.1,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = 0.625, log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
#Theorical points
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.1,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = 0.625, log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
#Theorical points
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.1,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = 0.625, log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
set.seed(5)
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
#Theorical points
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.1,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = 0.625, log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
#Theorical points
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.1,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = 0.625, log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
#Theorical points
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.1,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = 0.625, log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
#Theorical points
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.1,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = 0.625, log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
#Theorical points
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.1,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = 0.625, log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
#Theorical points
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.1,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = 0.625, log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
dataclt = 0
for (i in 1 : 1000) dataclt[i] = mean(rexp(40, lambda))
#Theorical points
x = seq(from = round(min(dataclt)), to = round(max(dataclt)), length.out = 1000)
#Plot
ggplot(as.data.frame(dataclt), aes(x=dataclt)) +
geom_histogram(aes(y=..density..),binwidth=0.1,colour="black", fill="white") +
geom_density(alpha=.2, fill="#FF6666",color = '#FF6666') +
stat_function(fun = function(x) dnorm(x, mean = 5, sd = 0.625, log = FALSE),colour = "blue") +
labs(title = "1000 averages of an Exponential Dist. vs A Normal Dist. (blue)", x = "x", y = "Density")
qnorm(dataclt)
library(datasets)
data(ToothGrowth)
library(datasets)
data <- data(ToothGrowth)
head(data)
library(datasets)
data(ToothGrowth)
head(ToothGrowth)
head(ToothGrowth)
summary(ToothGrowth)
View(ToothGrowth)
View(ToothGrowth)
t.test(len ~ supp, data = ToothGrowth)
View(ToothGrowth)
summary(ToothGrowth)
?ToothGrowth
t.test(len ~ supp, data = ToothGrowth)
View(ToothGrowth)
t.test(len ~ dose, data = ToothGrowth)
?pairwise.t.test
sapply(ToothGrowth, class)
pairwise.t.test(len, as.factor(dose))
View(ToothGrowth)
pairwise.t.test(ToothGrowth$len, as.factor(ToothGrowt$hdose))
pairwise.t.test(ToothGrowth$len, as.factor(ToothGrowth$dose))
?t.test
t.test(ToothGrowth$len, as.factor(ToothGrowth$supp)
)
t.test(ToothGrowth$len, ToothGrowth$supp)
t.test(ToothGrowth$len)
t.test(len ~ supp, data = ToothGrowth)
?pairwise.t.test
ToothGrowth_summary
summary <- ddply(ToothGrowth,.(dose, supp), summarize, mean = mean(len), sd = sd(len))
library(plyr)
summary <- ddply(ToothGrowth,.(dose, supp), summarize, mean = mean(len), sd = sd(len))
summary
?ddply
summary <- ddply(ToothGrowth,c(dose, supp), summarize, mean = mean(len), sd = sd(len))
summary <- ddply(ToothGrowth,c("dose", "supp"), summarize, mean = mean(len), sd = sd(len))
summary
View(ToothGrowth)
?t.test
t.test(len ~ supp, data = ToothGrowth, var.equal = T)
pairwise.t.test(ToothGrowth$len, ToothGrowth$dose)
?ToothGrowth
t.test(len ~ supp, data = ToothGrowth, var.equal = T, paired=T)
?pairwise.t.test
pairwise.t.test(ToothGrowth$len, ToothGrowth$dose, paired=T)
t.test(len ~ supp, data = ToothGrowth, var.equal = T, paired=T)
t.test(len ~ supp, data = ToothGrowth, var.equal = T, paired=T)
pairwise.t.test(ToothGrowth$len, ToothGrowth$dose, paired=T)
```
t.test(len ~ supp, data = ToothGrowth, var.equal = T, paired=T)
summary <- ddply(ToothGrowth,c("dose", "supp"), summarize, mean = mean(len), sd = sd(len))
summary
data(mtcars)
mtcars
model1 <- lm(mpg ~ factor(cyl), mtcars)
model2 <- lm(mpg ~ factor(cyl) + wt, mtcars)
model1
model2
model1 <- lm(mpg ~ factor(cyl) * wt, mtcars)
lrtest (model1, model2)
require(epicalc)
install.packages("epicalc")
library(epicalc)
anova)model1, model2)
anova(model1, model2)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y~x)
dfbeta(fit)
plot(x,y)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y~x)
fit
dfbetas(fit)
dfbeta(fit)
?dfbeta
?dfbetas
?dfbeta
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
View(segmentationOriginal)
train <- segmentationOriginal[segmentationOriginal$Case == "Train"]
train <- segmentationOriginal[segmentationOriginal$Case == "Train",]
test <- segmentationOriginal[segmentationOriginal$Case == "Test",]
set.seed(125)
?train
?CART
tree <- train(Class ~ ., method="rpart",data=segmentationOriginal)
tree
newdata <- C(TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2)
newdata <- C("TotalIntench2" = 23000, "FiberWidthCh1" = 10, "PerimStatusCh1" = 2)
newdata <- C("TotalIntench2" = 23000, "FiberWidthCh1" = 10, "PerimStatusCh1" = )
newdata <- data.frame("TotalIntench2" = 23000, "FiberWidthCh1" = 10, "PerimStatusCh1" = 2)
newdata
predict(tree,newdata=newdata)
newdata <- data.frame("TotalIntench2" = 50000, "FiberWidthCh1" = 10, "VarIntenCh4" = 100 )
newdata
predict(tree,newdata=newdata)
tree$finalmodel
tree
tree$finalModel
plot(tree$finalModel, uniform=T)
plot(tree$finalModel)
text(tree$finalModel, cex=0.8)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
library(pgmm)
data(olive)
olive = olive[,-1]
olive
View(olive)
tree <- train(Area ~ ., method="rpart", data=olive)
resul <- predict(tree, newdata = as.data.frame(t(colMeans(olive))))
resul
tree
plot(tree)
plot(tree$finalModel)text(tree$finalModel, cex=0.8)
plot(tree$finalModel)
text(tree$finalModel, cex=0.8)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
View(trainSA)
model <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", family="binomial", data=trainSA)
?train
?glm
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
predictTrain <- predict(model, trainSA)
predictTest <- predict(model, testSA)
missClass(trainSA$chd, predictTrain) # 0.2727273
missClass(testSA$chd, predictTest) # 0.3116883
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test
vowel.train
View(vowel.train)
sapply(vowel.test, class)
vowel.test$y <- as.factor(vowel.test$y)
sapply(vowel.test, class)
vowel.train$y <- as.factor(vowel.train$y)
sapply(vowel.train, class)
set.seed(33833)
model <- train(y ~ ., method="rf", data=vowel.train)
varImp(model)
library(caret)
library(ggplot2)
library(rattle)
#Load the dataset
setwd("C:/Users/dibujoatm/Dropbox/Practical Machine Learning")
train <- read.csv("pml-training.csv")
test <- read.csv("pml-testing.csv")
```
We loaded  the dataset and cleaned for its proper use. In the test data we select those variables that wont help us in our prediction and remove them from the  whole dataset. In the same manner we remove
```{r}
#Clean the data from the missing values in the test dataset
test <- test[,!sapply(test, function(x)all(is.na(x)))]
train <- train[,(names(train) %in% c(names(sapply(test, function(x)all(!is.na(x)))), "classe"))]
#Clean categorical variables columns 1:7
test <- test[ -c(1:7)]
train <- train[ -c(1:7)]
set.seed(123)
preProc <- preProcess(train[,-53],method="pca")
set.seed(123)
#Linear model
fit <- train(classe ~ ., method="rpart", preProcess="pca", data=train)
library(caret)
library(ggplot2)
library(rattle)
#Load the dataset
setwd("C:/Users/dibujoatm/Dropbox/Practical Machine Learning")
train <- read.csv("pml-training.csv")
finaltest <- read.csv("pml-testing.csv")
```
We loaded  the dataset and cleaned for its proper use. In the test data we select those variables that wont help us in our prediction and remove them from the  whole dataset. In the same manner we remove
```{r}
#Clean the data from the missing values in the test dataset
finaltest <- finaltest[,!sapply(finaltest, function(x)all(is.na(x)))]
train <- train[,(names(train) %in% c(names(sapply(finaltest, function(x)all(!is.na(x)))), "classe"))]
#Clean categorical variables columns 1:7
finaltest <- finaltest[ -c(1:7)]
train <- train[ -c(1:7)]
```
library(caret)
library(ggplot2)
library(rattle)
#Load the dataset
setwd("C:/Users/dibujoatm/Dropbox/Practical Machine Learning")
train <- read.csv("pml-training.csv")
finaltest <- read.csv("pml-testing.csv")
```
We loaded  the dataset and cleaned for its proper use. In the test data we select those variables that wont help us in our prediction and remove them from the  whole dataset. In the same manner we remove
```{r}
#Clean the data from the missing values in the test dataset
finaltest <- finaltest[,!sapply(finaltest, function(x)all(is.na(x)))]
train <- train[,(names(train) %in% c(names(sapply(finaltest, function(x)all(!is.na(x)))), "classe"))]
#Clean categorical variables columns 1:7
finaltest <- finaltest[ -c(1:7)]
train <- train[ -c(1:7)]
```
library(caret)
library(ggplot2)
library(rattle)
#Load the dataset
setwd("C:/Users/dibujoatm/Dropbox/Practical Machine Learning")
train <- read.csv("pml-training.csv")
finaltest <- read.csv("pml-testing.csv")
```
We loaded  the dataset and cleaned for its proper use. In the test data we select those variables that wont help us in our prediction and remove them from the  whole dataset. In the same manner we remove
```{r}
#Clean the data from the missing values in the test dataset
finaltest <- finaltest[,!sapply(finaltest, function(x)all(is.na(x)))]
train <- train[,(names(train) %in% c(names(sapply(finaltest, function(x)all(!is.na(x)))), "classe"))]
library(caret)
library(ggplot2)
library(rattle)
setwd("C:/Users/dibujoatm/Dropbox/Practical Machine Learning")
train <- read.csv("pml-training.csv")
finaltest <- read.csv("pml-testing.csv")
finaltest <- finaltest[,!sapply(finaltest, function(x)all(is.na(x)))]
train <- train[,(names(train) %in% c(names(sapply(finaltest, function(x)all(!is.na(x)))), "classe"))]
finaltest <- finaltest[ -c(1:7)]
train <- train[ -c(1:7)]
nearZeroVar(train, saveMetrics=TRUE)
sapply(train, class)
control <- trainControl(method="cv", 5)
fit <- train(classe ~ ., data=train, method="rf", preProcess="pca", trControl=control)
control <- trainControl(method="cv", 10)
fit <- train(classe ~ ., data=train, method="rpart", preProcess="pca", trControl=control)
fit
control <- trainControl(method="cv", 10)
fit <- train(classe ~ ., data=train, method="rpart", trControl=control)
fit
fit <- train(classe ~ ., data=train, method="rf", trControl=control)
fit <- train(classe ~ ., data=train, method="rf", preProcess="pca" trControl=control)
fit <- train(classe ~ ., data=train, method="rf", preProcess="pca", trControl=control)
?rf
colnames(train)
colnames(train[,-53])
control <- trainControl(method="cv", 10)
fit <- train(classe ~ ., data=train, method="rpart", preProcess="pca", trControl=control, ntree=100)
fit <- train(classe ~ ., data=train, method="rf", trControl=control, ntree = 100)
fit <- train(classe ~ ., data=train, method="rf", trControl=control, prox=TRUE, allowParallel=TRUE)
fit <- train(classe ~ ., data=train, method="rf", trControl=control, prox=TRUE, allowParallel=TRUE)
sys.time(2+2)
systime(2+2)
systen.time(2+2)
systen.time(2)
systen.time()
system.time(2+2)
system.time(2^2312)
system.time(2^2315435435)
system.time(2^2315435435453463643)
system.time(fit)
system.time(4325432345235^5325)
system.time(read.csv("pml-training.csv"))
fittime <- system.time(train(classe ~ ., data=train, method="rf", trControl=control, prox=TRUE, allowParallel=TRUE))
library(ggplot2)
library(GGally)
install.packages("GGally)")
install.packages("GGally")
library(ggplot2)
library(GGally)
data(mtcars)
head(mtcars, 3)
sapply(mtcars, class)
g <- ggplot(mtcars, aes(factor(am), mpg))
g + geom_boxplot(aes(fill = am)) + ggtitle("Box plot for MPG vs Transmission") + xlab("Transmission type") + ylab("Miles per gallon")
library(ggplot2)
library(GGally)
data(mtcars)
head(mtcars, 3)
sapply(mtcars, class)
mtcars$am[mtcars$am == 0] <- "automatic"
mtcars$am[mtcars$am == 1] <- "manual"
mtcars$cyl <- factor(mtcars$cyl)
mtcars$vs <- factor(mtcars$vs)
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
mtcars$am <- factor(mtcars$am)
g <- ggplot(mtcars, aes(factor(am), mpg))
g + geom_boxplot(aes(fill = am)) + ggtitle("Box plot for MPG vs Transmission") + xlab("Transmission type") + ylab("Miles per gallon")
library(dplyr)
?ddply
ddply(mtcars, c("mpg","am"), summarise, mean = mean(mpg), sd = sd(mpg))
library(dplyr)
ddply(mtcars, c("mpg","am"), summarise, mean = mean(mpg), sd = sd(mpg))
?ddply
ddply(mtcars, c("mpg","am"), summarise, mean = mean(mpg), sd = sd(mpg))
